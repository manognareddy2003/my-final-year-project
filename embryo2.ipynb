{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69f25816",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\users\\asus\\python376\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\asus\\python376\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\asus\\python376\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\asus\\python376\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\asus\\python376\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\asus\\python376\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\users\\asus\\python376\\lib\\site-packages\\google\\auth\\crypt\\_cryptography_rsa.py:22: CryptographyDeprecationWarning: Python 3.7 is no longer supported by the Python core team and support for it is deprecated in cryptography. A future release of cryptography will remove support for Python 3.7.\n",
      "  import cryptography.exceptions\n",
      "c:\\users\\asus\\python376\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\asus\\python376\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\asus\\python376\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\asus\\python376\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\asus\\python376\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\asus\\python376\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense,Activation,Dropout, Flatten\n",
    "import seaborn as sns\n",
    "import os\n",
    "import cv2\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "import pickle\n",
    "from keras.models import model_from_json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b6a858a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r\"augmented_images\"\n",
    "model_folder = \"Model2\"\n",
    "#This will be used as the folder name where the model will be stored.\n",
    "categories = [d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fe3e76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X and Y arrays loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "X_file = os.path.join(model_folder, \"X.txt.npy\") ## Construct file paths for loading and saving NumPy arrays\n",
    "Y_file = os.path.join(model_folder, \"Y.txt.npy\")\n",
    "if os.path.exists(X_file) and os.path.exists(Y_file): ## Check if the files alreadyexist\n",
    "    X = np.load(X_file)\n",
    "    Y = np.load(Y_file) ## Load the arrays from the files\n",
    "    print(\"X and Y arrays loaded successfully.\")\n",
    "else:\n",
    "    ## Initialize empty arrays for input and output\n",
    "    X = [] # input array\n",
    "    Y = [] # output array\n",
    "    # Traverse through the directory specified by 'path'\n",
    "    for root, dirs, directory in os.walk(path):\n",
    "    # Loop through the files in the directory\n",
    "        for j in range(len(directory)):\n",
    "            name = os.path.basename(root)      #extract the category name from the directory path\n",
    "            print(f'Loading category: {dirs}')     # Print the category being loaded\n",
    "            print(name+\" \"+root+\"/\"+directory[j])    # Print the path of the current image being loaded\n",
    "            if 'Thumbs.db' not in directory[j]:     ## Check if the current file is not 'Thumbs.db'\n",
    "                img_array = cv2.imread(root+\"/\"+directory[j])   ## Read the image fileusing OpenCV\n",
    "                img_resized = cv2.resize(img_array, (64,64))   # Resize the image to 64x64 pixels\n",
    "                im2arr = np.array(img_resized)      # Convert the resized image to a NumPy array\n",
    "                im2arr = im2arr.reshape(64,64,3)    # Reshape the array to match theexpected input shape (64x64x3)\n",
    "                X.append(im2arr)       # Append the index of the category in categories list to Y\n",
    "                Y.append(categories.index(name)) # Append the index of the category incategories list to the output array (Y)\n",
    "    X = np.asarray(X)        ## Convert the lists to NumPy arrays\n",
    "    Y = np.asarray(Y)\n",
    "    X = X.astype('float32')      # Convert pixel values to float32 and normalize them to arange between 0 and 1\n",
    "    X = X / 255               # Normalize pixel values\n",
    "    Y = to_categorical(Y, num_classes=len(categories))         # Convert labels to one-hot encoding\n",
    "## Save the processed arrays to files\n",
    "    np.save(X_file, X)\n",
    "    np.save(Y_file, Y)\n",
    "    print(\"X and Y arrays saved successfully.\")\n",
    "# Shuffle the data using randomly generated indices\n",
    "indices = np.arange(X.shape[0]) # it give shape of that matrix\n",
    "np.random.shuffle(indices)\n",
    "X = X[indices]\n",
    "Y = Y[indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b66fbb3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(categories)\n",
    "num_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76b6fbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.20,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40181e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Example class labels, modify as necessary\n",
    "labels = ['0', '1']  \n",
    "accuracy, precision, recall, fscore = [], [], [], []  # Lists to store metrics\n",
    "\n",
    "def calculateMetrics(algorithm, predict, testY, labels):\n",
    "    testY = testY.astype('int')\n",
    "    predict = predict.astype('int')\n",
    "\n",
    "    # Calculate metrics\n",
    "    a = accuracy_score(testY, predict) * 100\n",
    "    p = precision_score(testY, predict, average='macro') * 100\n",
    "    r = recall_score(testY, predict, average='macro') * 100\n",
    "    f = f1_score(testY, predict, average='macro') * 100\n",
    "\n",
    "    # Append metrics to lists\n",
    "    accuracy.append(a)\n",
    "    precision.append(p)\n",
    "    recall.append(r)\n",
    "    fscore.append(f)\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"{algorithm} Accuracy: {a:.2f}\")\n",
    "    print(f\"{algorithm} Precision: {p:.2f}\")\n",
    "    print(f\"{algorithm} Recall: {r:.2f}\")\n",
    "    print(f\"{algorithm} F1 Score: {f:.2f}\")\n",
    "    print(f\"\")\n",
    "    print(f\"\")\n",
    "\n",
    "    # Classification report\n",
    "    report = classification_report(testY, predict, target_names=labels, output_dict=True)\n",
    "    conf_matrix = confusion_matrix(testY, predict)\n",
    "   # Compute and print per-class metrics\n",
    "    print(f\"{algorithm} Classification Report:\")\n",
    "    print(f\"\")\n",
    "\n",
    "    class_accuracy = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n",
    "    print(f\"{'Class':<10}{'Accuracy':<10}{'Precision':<10}{'Recall':<10}{'F1 Score':<10}\")\n",
    "    for i, class_name in enumerate(labels):\n",
    "        print(f\"{class_name:<10}{class_accuracy[i]:<10.4f}{report[class_name]['precision']:<10.4f}{report[class_name]['recall']:<10.4f}{report[class_name]['f1-score']:<10.4f}\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(f\"{algorithm} Confusion Matrix\")\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.show()\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c488c9e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd12e902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\apple\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\apple\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               1605888   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 1,616,546\n",
      "Trainable params: 1,616,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "CNN Model Prediction Accuracy = 93.51415038108826\n"
     ]
    }
   ],
   "source": [
    "# Check if the pkl file exists\n",
    "Model_file = os.path.join(model_folder, \"DLmodel.json\") # Check if the JSON filefor the model exists\n",
    "\n",
    "## Constructs the file path for the model's JSON file within the specified model folder.\n",
    "Model_weights = os.path.join(model_folder, \"DLmodel_weights.h5\") #weights filewithin the specified model folder.\n",
    "\n",
    "Model_history = os.path.join(model_folder, \"history.pckl\") # Constructs the file path for the model's training history file within the specified model folder.\n",
    "if os.path.exists(Model_file):\n",
    "        # Checks if the JSON file for the model exists.\n",
    "    with open(Model_file, \"r\") as json_file:\n",
    "    # Opens the JSON file for reading.\n",
    "        loaded_model_json = json_file.read()\n",
    "    # Reads the contents of the JSON file into a string.\n",
    "        model = model_from_json(loaded_model_json)\n",
    "    # Constructs a model from the JSON string representation.\n",
    "    json_file.close()\n",
    "    json_file.close()\n",
    "    model.load_weights(Model_weights)\n",
    "        ## Loads the weights of the model from the specified weights file.\n",
    "    model._make_predict_function()\n",
    "    print(model.summary())\n",
    "    f = open(Model_history, 'rb') # Opens the training history file for reading in binary mode.\n",
    "    accuracy = pickle.load(f) # Loads the training history dictionary from the pickle file.\n",
    "    f.close() # Closes the history file.\n",
    "    acc = accuracy['accuracy']\n",
    "    acc = acc[9] * 100 # Selects the accuracy value corresponding to the 10thepoch and converts it to a percentage.\n",
    "    print(\"CNN Model Prediction Accuracy = \" + str(acc))\n",
    "else:\n",
    "    # If the model files do not exist, create and train a new model.\n",
    "    model = Sequential() #resnet transfer learning code here\n",
    "    model.add(Convolution2D(32, 3, 3, input_shape = (64, 64, 3), activation = 'relu'))\n",
    "    # Adds a 2D convolutional layer with 32 filters, a 3x3 kernel size, and ReLU activation.\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    model.add(Convolution2D(32, 3, 3, activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(output_dim = 256, activation = 'relu'))\n",
    "    # Adds a fully connected layer with 256 neurons and ReLU activation.\n",
    "    model.add(Dense(output_dim = num_classes, activation = 'softmax')) # optimizer use is minimizing the loss function\n",
    "    # Adds an output layer with 'num_classes' neurons and softmax activation.\n",
    "    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    print(model.summary())\n",
    "    #hist = model.fit(X, Y, batch_size=16, epochs=10, validation_split=0.2, shuffle=True,verbose=2)\n",
    "    hist = model.fit(X_train, Y_train, batch_size=16, epochs=50, validation_data=(X_test, Y_test), shuffle=True, verbose=2)\n",
    "    # Trains the model with the specified training data for 25 epochs, with batch size 16, and validates on test data\n",
    "    model.save_weights(Model_weights) # Saves the trained model weights\n",
    "    model_json = model.to_json() ## Converts the model to JSON format.\n",
    "    with open(Model_file, \"w\") as json_file:\n",
    "    # Opens the JSON file for writing.\n",
    "        json_file.write(model_json)\n",
    "    json_file.close()\n",
    "    f = open(Model_history, 'wb')\n",
    "    pickle.dump(hist.history, f)\n",
    "    f.close()\n",
    "    f = open(Model_history, 'rb') # Opens the history file for writing in binary mode.\n",
    "    accuracy = pickle.load(f) # Saves the training history dictionary to the file\n",
    "\n",
    "    f.close()\n",
    "    acc = accuracy['accuracy']\n",
    "    acc = acc[9] * 100\n",
    "    print(\"CNN Model Prediction Accuracy = \"+str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9118f8a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10816\\941974186.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Run the function to calculate metrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mcalculateMetrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"CNN Model\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategories\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10816\\2256751603.py\u001b[0m in \u001b[0;36mcalculateMetrics\u001b[1;34m(algorithm, predict, testY, labels)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m# Append metrics to lists\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0maccuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mprecision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mrecall\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Generate predictions and convert them to class labels\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# If y_test and y_pred_classes are one-hot encoded, convert them to class labels\n",
    "if Y_test.ndim > 1 and Y_test.shape[1] > 1:\n",
    "    Y_test = np.argmax(Y_test, axis=1)\n",
    "\n",
    "# Define categories or use the previously defined labels\n",
    "categories = ['0', '1']  # Adjust to match your actual class names\n",
    "\n",
    "# Run the function to calculate metrics\n",
    "calculateMetrics(\"CNN Model\", y_pred_classes, Y_test, categories)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af352201",
   "metadata": {},
   "source": [
    "## test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a0e6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = r'testimges/1.jpg'\n",
    "img = cv2.imread(path)\n",
    "img_resized = cv2.resize(img, (64,64))    # every image in different size hence we resize the image.\n",
    "im2arr = np.array(img_resized)           # Convert the resized image into a NumPy array\n",
    "img_reshaped = im2arr.reshape(1,64,64,3)         ### Reshape the NumPy array to match the expected input shape of the model (1, 64, 64, 3)\n",
    "\n",
    "test = np.asarray(img_reshaped)\n",
    "# Convert the reshaped image array into a NumPy array\n",
    "\n",
    "test = test.astype('float32')\n",
    "test = test/255\n",
    "pred_probability = model.predict(test)\n",
    "pred_number = np.argmax(pred_probability)   #argmax is a fundamental function in deeplearning for\n",
    "\n",
    "# converting probability distributions into class labels\n",
    "## This returns the index of the maximum value in the pred_probability array,\n",
    "# which corresponds to the predicted class label.\n",
    "\n",
    "output_name=categories[pred_number] # Get the corresponding output class name basedon the index\n",
    "plt.imshow(img)\n",
    "plt.text(10, 10, f'Predicted Output: {output_name}', color='white', fontsize=12, weight='bold', backgroundcolor='black')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27604da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = r'testimges/20.jpg'\n",
    "img = cv2.imread(path)\n",
    "img_resized = cv2.resize(img, (64,64))    # every image in different size hence we resize the image.\n",
    "im2arr = np.array(img_resized)           # Convert the resized image into a NumPy array\n",
    "img_reshaped = im2arr.reshape(1,64,64,3)         ### Reshape the NumPy array to match the expected input shape of the model (1, 64, 64, 3)\n",
    "\n",
    "test = np.asarray(img_reshaped)\n",
    "# Convert the reshaped image array into a NumPy array\n",
    "\n",
    "test = test.astype('float32')\n",
    "test = test/255\n",
    "pred_probability = model.predict(test)\n",
    "pred_number = np.argmax(pred_probability)   #argmax is a fundamental function in deeplearning for\n",
    "\n",
    "# converting probability distributions into class labels\n",
    "## This returns the index of the maximum value in the pred_probability array,\n",
    "# which corresponds to the predicted class label.\n",
    "\n",
    "output_name=categories[pred_number] # Get the corresponding output class name basedon the index\n",
    "plt.imshow(img)\n",
    "plt.text(10, 10, f'Predicted Output: {output_name}', color='white', fontsize=12, weight='bold', backgroundcolor='black')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5537d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = r'testimges/22.jpg'\n",
    "img = cv2.imread(path)\n",
    "img_resized = cv2.resize(img, (64,64))    # every image in different size hence we resize the image.\n",
    "im2arr = np.array(img_resized)           # Convert the resized image into a NumPy array\n",
    "img_reshaped = im2arr.reshape(1,64,64,3)         ### Reshape the NumPy array to match the expected input shape of the model (1, 64, 64, 3)\n",
    "\n",
    "test = np.asarray(img_reshaped)\n",
    "# Convert the reshaped image array into a NumPy array\n",
    "\n",
    "test = test.astype('float32')\n",
    "test = test/255\n",
    "pred_probability = model.predict(test)\n",
    "pred_number = np.argmax(pred_probability)   #argmax is a fundamental function in deeplearning for\n",
    "\n",
    "# converting probability distributions into class labels\n",
    "## This returns the index of the maximum value in the pred_probability array,\n",
    "# which corresponds to the predicted class label.\n",
    "\n",
    "output_name=categories[pred_number] # Get the corresponding output class name basedon the index\n",
    "plt.imshow(img)\n",
    "plt.text(10, 10, f'Predicted Output: {output_name}', color='white', fontsize=12, weight='bold', backgroundcolor='black')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b70a0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = r'testimges/17.jpg'\n",
    "img = cv2.imread(path)\n",
    "img_resized = cv2.resize(img, (64,64))    # every image in different size hence we resize the image.\n",
    "im2arr = np.array(img_resized)           # Convert the resized image into a NumPy array\n",
    "img_reshaped = im2arr.reshape(1,64,64,3)         ### Reshape the NumPy array to match the expected input shape of the model (1, 64, 64, 3)\n",
    "\n",
    "test = np.asarray(img_reshaped)\n",
    "# Convert the reshaped image array into a NumPy array\n",
    "\n",
    "test = test.astype('float32')\n",
    "test = test/255\n",
    "pred_probability = model.predict(test)\n",
    "pred_number = np.argmax(pred_probability)   #argmax is a fundamental function in deeplearning for\n",
    "\n",
    "# converting probability distributions into class labels\n",
    "## This returns the index of the maximum value in the pred_probability array,\n",
    "# which corresponds to the predicted class label.\n",
    "\n",
    "output_name=categories[pred_number] # Get the corresponding output class name basedon the index\n",
    "plt.imshow(img)\n",
    "plt.text(10, 10, f'Predicted Output: {output_name}', color='white', fontsize=12, weight='bold', backgroundcolor='black')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b71016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Set image dimensions\n",
    "img_width, img_height = 64, 64\n",
    "input_shape = (img_width, img_height, 3)\n",
    "\n",
    "# Load and preprocess image data\n",
    "data_dir =r\"Dataset/\"  # Replace with your dataset path\n",
    "\n",
    "# Use ImageDataGenerator to load and preprocess images\n",
    "datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    directory=os.path.join(data_dir, 'train'),\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    directory=os.path.join(data_dir, 'test'),\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Extract features and labels from generators\n",
    "x_train, y_train = next(train_generator)\n",
    "x_test, y_test = next(test_generator)\n",
    "\n",
    "# Build a CNN model for feature extraction\n",
    "def build_cnn_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    return model\n",
    "\n",
    "# Initialize CNN model\n",
    "cnn_model = build_cnn_model(input_shape)\n",
    "\n",
    "# Extract features using the CNN model (ignore the final dense layer for feature extraction)\n",
    "cnn_feature_extractor = Sequential(cnn_model.layers[:-1])  # Exclude the final dense layer\n",
    "\n",
    "# Extract features from CNN model\n",
    "x_train_features = cnn_feature_extractor.predict(x_train)\n",
    "x_test_features = cnn_feature_extractor.predict(x_test)\n",
    "\n",
    "# Define the path to save/load the hybrid model\n",
    "hybrid_model_path = 'model/hybrid_model_image.npy'\n",
    "\n",
    "# Train CatBoost if the model is not already saved\n",
    "if os.path.exists(hybrid_model_path):\n",
    "    hybrid_model = CatBoostClassifier().load_model(hybrid_model_path)\n",
    "else:\n",
    "    hybrid_model = CatBoostClassifier()\n",
    "    hybrid_model.fit(x_train_features, y_train, verbose=False)\n",
    "    hybrid_model.save_model(hybrid_model_path)\n",
    "\n",
    "# Predict and evaluate the hybrid model\n",
    "y_pred_hybrid = hybrid_model.predict(x_test_features)\n",
    "hybrid_model_accuracy = accuracy_score(y_test, y_pred_hybrid)\n",
    "\n",
    "print(\"Hybrid Model (Image) Accuracy:\", hybrid_model_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1164df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the image path and categories\n",
    "path = r'testimges/17.jpg'\n",
    "categories = ['0', '1']  # Replace with your actual class names\n",
    "\n",
    "# Load and preprocess the image\n",
    "img = cv2.imread(path)\n",
    "\n",
    "# Check if the image was loaded successfully\n",
    "if img is None:\n",
    "    print(\"Error: Image not found or could not be loaded. Check the file path.\")\n",
    "else:\n",
    "    # Proceed only if the image was loaded correctly\n",
    "    img_resized = cv2.resize(img, (64, 64))  # Resize the image to match the input shape\n",
    "    img_array = np.array(img_resized)        # Convert the resized image into a NumPy array\n",
    "    img_reshaped = img_array.reshape(1, 64, 64, 3)  # Reshape to match the CNN input shape\n",
    "\n",
    "    # Normalize the image data\n",
    "    test_img = img_reshaped.astype('float32') / 255.0\n",
    "\n",
    "    # Extract features using the CNN model (cnn_feature_extractor is used for feature extraction)\n",
    "    test_features = cnn_feature_extractor.predict(test_img)\n",
    "\n",
    "    # Predict using CatBoost with extracted features\n",
    "    pred_probability = hybrid_model.predict_proba(test_features)\n",
    "    pred_number = np.argmax(pred_probability)  # Get the class with the highest probability\n",
    "\n",
    "    # Get the predicted class label\n",
    "    output_name = categories[pred_number]\n",
    "\n",
    "    # Display the image and prediction\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))  # Convert color for correct display\n",
    "    plt.text(10, 10, f'Predicted Output: {output_name}', color='white', fontsize=12, weight='bold', backgroundcolor='black')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5673e20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
